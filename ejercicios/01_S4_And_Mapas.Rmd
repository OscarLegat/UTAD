---
title: "01_S4_&_Mapas.Rmd"
output: html_document
---

Muestra la evolución geolocalizada de las Retenciones de tráfico extraidos de los tweets de INFODGT.
Pare extraer los datos es necesarios conectarse a Twitter con las necesarias autenticaciones. En el
caso de que no dispongamos de las mismas, el código obtiene los Tweets de los previemante obtenidos
,de la cuenta de GitHub de OscarLegat.
Igualmente los mapas sobre los que se geolocalizan los puntos, están alojados en la cuenta de GitHub de
OscarLegat.
Tanto los puntos como los mapas, para poder ser puestos los unos sobre los otros, es necesrio  que
dispongan del mismo sistema de coordenadas.
Todos los datos descargados son colocados en el directorio de trabajo actual, en un directorio que se 
llama "datos_OscarUTAD". Todos los ejercicios utilizan este directorio. Si no existe el directorio se
crea solo. Una vez terminada la ejecución, se puede eliminar este directorio.


Load packages:

```{r Load packages}
#Load packages

if (!(require("devtools", character.only=T, quietly=T))) {
  install.packages("devtools")
  library("devtools", character.only=T)
}

if (!(require("data.table", character.only=T, quietly=T))) {
  install.packages("data.table")
  library("data.table", character.only=T)
}
if (!(require("rgdal", character.only=T, quietly=T))) {
  install.packages("rgdal")
  library("rgdal", character.only=T)
}

if (!(require("sp", character.only=T, quietly=T))) {
  install.packages("sp")
  library("sp", character.only=T)
}
if (!(require("twitteR", character.only=T, quietly=T))) {
  install.packages("twitteR")
  library("twitteR", character.only=T)
}
if (!(require("ggplot2", character.only=T, quietly=T))) {
  install.packages("ggplot2")
  library("ggplot2", character.only=T)
}
```


Get data:

```{r Get data:}
#Get data
URLBase <- "https://raw.githubusercontent.com/OscarLegat/UTAD/master/downloads/"
dirWorking <- getwd()
dirDataBase <- "datos_OscarUTAD"
dirPathDataBase = paste0(dirWorking, "/", dirDataBase)
destDirectoryESP_adm = paste0(dirPathDataBase, "/", "ESP_adm")


if (!file.exists(dirPathDataBase)){
  dir.create(file.path(dirWorking, dirDataBase))
} 


file <- paste0(URLBase,  "ESP_adm.zip")
destfileZip = paste0(dirPathDataBase,"/","ESP_adm.zip")
download.file(file, destfile = destfileZip,method = "curl", quiet = FALSE, mode = "w",cacheOK = TRUE,extra = getOption("download.file.extra"))
unzip(destfileZip, exdir=dirPathDataBase)

```



Connect to Twitter:

```{r Connect to Twitter:}
#Authentication twitter variables

api_key <- "XXXXXM40dwRnETT"
api_secret <- "XXXXXXeQbx6dmR4kpUyZB"
access_token <- "XXXXX102146506-w01"
access_token_secret <- "XXXXXX6hFuJru7PBcisF2o4Fn"

#download.file(url="http://curl.haxx.se/ca/cacert.pem",destfile="cacert.pem")
#Authenticate in twitter

#Use direct authentication option
options(httr_oauth_cache=T)
result = tryCatch({
  setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
  'OK'
}, error = function(e) {
  'ERROR'
})

```


Execute query in twitter:

```{r Execute query in twitter:}

if(result != 'ERROR'){
  searchQ <- "@InformacionDGT#RETENCIÓN"
  tweets <- searchTwitteR(searchQ, n=2000, since ='2015-05-25')
}
```


Tweets to datatable:

```{r Tweets to datatable:}

if(result != 'ERROR'){
  df.tweets <- twListToDF(tweets)
  dt.tweets <- as.data.table(df.tweets)
}

```

Functions to get fields to study:

```{r Functions to get fields to study:}
#Teewts parse functions
if(result != 'ERROR'){
  
  #Teewts parse functions
  tweet_get_latitude <- function(x){
    aux1 <- unlist(strsplit(x$urls$expanded_url,'lat='))
    lat <- as.numeric(unlist(strsplit(aux1[2],'&'))[1])
    return(lat)
  }
  
  tweet_get_longitude <- function(x){
    aux2 <- unlist(strsplit(x$urls$expanded_url,'lng='))
    lng <- as.numeric(unlist(strsplit(aux2[2],'&'))[1])
    return(lng)
  }
  
  tweet_get_mon <- function(x){
    month <- as.numeric(as.POSIXlt(x$created)$mon+1)
    return(month)
  }
  
  
  tweet_get_day <- function(x){
    day <- as.numeric(as.POSIXlt(x$created)$mday)
    return(day)
  }
  
  
  tweet_get_year <- function(x){
    year <- as.numeric(as.POSIXlt(x$created)$year+1900)
    return(year)
  }
  
  
  tweet_get_color <- function(x){
    aux <- unlist(strsplit(x$text,'nivel '))
    color <- as.character(unlist(strsplit(aux[2],' '))[1])
    if(is.na(color)){
      color <- 'red'
    }else if(color == 'ROJO'){
      color <- 'orange'
    }else if(color == 'AMARILLO'){
      color <- 'yellow'
    }else{
      color <- 'red'
    }
    return(color)
  }
  
  
  
  tweet_get_dataTable <- function(x){
    
    lat <- tweet_get_latitude(x[[1]])
    lng <- tweet_get_longitude(x[[1]])
    mon <- tweet_get_mon(x[[1]])
    day <- tweet_get_day(x[[1]])
    year <- tweet_get_year(x[[1]])
    date <- paste0(year,"-", mon,"-", day)
    color_ <- tweet_get_color(x[[1]])    
    
    
    datFrame <- as.data.frame(list(1, mon, lat, lng, color_, date))
    colnames(datFrame) <- c("id", "mon","latitude","longitude", "color_", "date")
    
    for(i in 2:length(x)){
      
      if(length(x[[i]]$urls$expanded_url) > 0){
        
        lat <- tweet_get_latitude(x[[i]])
        lng <- tweet_get_longitude(x[[i]])
        mon <- tweet_get_mon(x[[i]])
        day <- tweet_get_day(x[[i]])
        year <- tweet_get_year(x[[i]])
        date <- paste0(year,"-", mon,"-", day)
        color_ <- tweet_get_color(x[[i]])    
        
        if(!is.na(lat) &&  !is.na(lng) && !is.na(mon)){
          dati <- as.data.frame(list(i, mon, lat, lng, color_, date))
          colnames(dati) <- c("id", "mon","latitude","longitude", "color_","date")
          datFrame <- rbind(datFrame, dati)      
        }
        
      }
    }
    
    return (as.data.table(datFrame))
  }
}  

```

Load coordinates data:

```{r Load coordinates data:}
#Load data points
counties<-readOGR(dsn = destDirectoryESP_adm, "ESP_adm1")
#Max Y Islas
ymax <- summary(counties[counties$NAME_1 == 'Islas Canarias',])$bbox[2,2] #y max
counties <- counties[counties$NAME_1 != 'Islas Canarias',]
proj4string(counties)


if(result != "ERROR"){
  datatable <- tweet_get_dataTable(tweets)
  write.csv(datatable, file = paste0(destDirectoryESP_adm,"/","tweets.csv"))
}else{
  datatable <- as.data.table(fread(paste0(destDirectoryESP_adm,"/","tweets.csv")))
}

#write.csv(datatable, file = paste0(destDirectoryESP_adm,"/","tweets.csv"))
#datatable <- as.data.table(fread(paste0(destDirectoryESP_adm,"/","tweets.csv")))

mapdata <- copy(datatable)
coordinates(mapdata) <-  c("latitude", "longitude") 

proj4string(mapdata)
proj4string(mapdata)<-CRS("+proj=longlat +datum=WGS84")
mapdata<-spTransform(mapdata, CRS(proj4string(counties)))



identical(proj4string(mapdata),proj4string(counties))

counties_fortify <- as.data.table(fortify(counties))

mapdata<-as.data.table(data.frame(mapdata))


names(mapdata)[names(mapdata)=="longitude"]<-"x"
names(mapdata)[names(mapdata)=="latitude"]<-"y"

mapdata <- mapdata[mapdata$y > ymax]

mapdata$color_ = factor(mapdata$color_)

```

PLot the map:


```{r qplot PLot the map:}
#Plot1
plot <- ggplot() +  
  geom_path(data=counties_fortify, aes(x=long, y=lat, group=group), fill="grey40", 
            colour="black", alpha=1)+
  labs(x="", y="", title="Evolución de \'Retenciones\' según Tweets de InfoDGT")+ #labels
  theme(axis.ticks.y = element_blank(),axis.text.y = element_blank(), # get rid of x ticks/text
        axis.ticks.x = element_blank(),axis.text.x = element_blank(), # get rid of y ticks/text
        plot.title = element_text(lineheight=.8, face="bold", vjust=1))+ # make title bold and add space
  geom_point(aes(x=x, y=y, color=color_), data=mapdata, alpha=1, size=3, color="grey20")+# to get outline
  geom_point(aes(x=x, y=y, color=color_), data=mapdata, alpha=1, size=2) +coord_equal(ratio=1) + facet_wrap(~date) + 
  scale_color_manual(name="Niveles de Retención",values = levels(mapdata$color_), labels = c("Retención Alta", "Corte", "Retención"))

print(plot)
```